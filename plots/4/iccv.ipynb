{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1. RUN THE CELLS SEQUENTIALLY TO AVOID ANY IMPEDIMENTS\n",
    "2. READ THE INSTRUCTIONS IN EACH CELL CAREFULLY\n",
    "3. IN THE ABSENCE OF ANY INSTRUCTIONS, YOU MAY PROCEED TO RUN IT\n",
    "\n",
    "This plot comprises the scatter plot for the β and α values corresponding to paradigm-I (5 classes)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import scienceplots\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import shutil\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "plt.style.use([\"science\", \"no-latex\"])\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.spines.top'] = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_res(save_loc, dest_folder=None):\n",
    "    if dest_folder is not None:\n",
    "        os.makedirs(dest_folder, exist_ok=True)\n",
    "        shutil.copy(\"results/{}\".format(save_loc), dest_folder)\n",
    "\n",
    "    with open(\"results/{}\".format(save_loc), \"rb\") as f:\n",
    "        res = pickle.load(f)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def avg_across_dicts(dicts):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        dicts: list of dictionaries with same keys and lists as elements\n",
    "\n",
    "    Returns:\n",
    "        single dict with the keys and average of lists\n",
    "\n",
    "    \"\"\"\n",
    "    avg_dict = dict()\n",
    "    keys = dicts[0].keys()\n",
    "    for k in keys:\n",
    "        values = []\n",
    "        for d in dicts:\n",
    "            values.append(d[k])\n",
    "        avg_dict[k] = np.mean(values, axis=0)\n",
    "\n",
    "    return avg_dict\n",
    "\n",
    "\n",
    "def str_contains(word_list, string):\n",
    "    for word in word_list:\n",
    "        if word not in string:\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "def sort_first_five_characters(string):\n",
    "    sorted_chars = ''.join(sorted(string[:5]))\n",
    "    sorted_string = sorted_chars + string[5:]\n",
    "    return sorted_string\n",
    "\n",
    "def remove_duplicate_keys(dictionary):\n",
    "    dictionary = {sort_first_five_characters(k): v for k, v in dictionary.items()}\n",
    "    unique_keys = set(dictionary.keys())\n",
    "    new_dictionary = {key: dictionary[key] for key in unique_keys}\n",
    "    return new_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. This section is for the F-score bar plots for 5 classes and 10 classes ~ stream learning\n",
    "# 2. Select algorithm type; 'naive' here corresponds to 'vanilla' in the ICCV paper\n",
    "# 3. Select dtype (_5 for paradigm-I and _10 for paradigm-II)\n",
    "_alg_type = \"naive\" # naive / ewc / lwf\n",
    "dtype = \"cifar_5\" # mnist_5 / fmnist_5 / cifar_5 / mnist_10 / fmnist_10 / cifar_10\n",
    "\n",
    "indicators, t1_indicators = None, None\n",
    "\n",
    "if dtype == \"fmnist_5\":\n",
    "    indicators = [\"mnist.FashionMNIST\", \"classes.5\", \"-avg\"]\n",
    "    t1_indicators = [\"mnist.FashionMNIST\", \"classes.5\", \"-t1\"]\n",
    "elif dtype == \"fmnist_10\":\n",
    "    indicators = [\"mnist.FashionMNIST\", \"classes.10\", \"-avg\"]\n",
    "    t1_indicators = [\"mnist.FashionMNIST\", \"classes.10\", \"-t1\"]\n",
    "elif dtype == \"mnist_5\":\n",
    "    indicators = [\"mnist.MNIST\", \"classes.5\", \"-avg\"]\n",
    "    t1_indicators = [\"mnist.FashionMNIST\", \"classes.5\", \"-t1\"]\n",
    "elif dtype == \"mnist_10\":\n",
    "    indicators = [\"mnist.MNIST\", \"classes.10\", \"-avg\"]\n",
    "    t1_indicators = [\"mnist.FashionMNIST\", \"classes.10\", \"-t1\"]\n",
    "elif dtype == \"cifar_5\":\n",
    "    indicators = [\"cifar.CIFAR10\", \"classes.5\", \"-avg\"]\n",
    "    t1_indicators = [\"cifar.CIFAR10\", \"classes.5\", \"-t1\"]\n",
    "elif dtype == \"cifar_10\":\n",
    "    indicators = [\"cifar.CIFAR10\", \"classes.10\", \"-avg\"]\n",
    "    t1_indicators = [\"cifar.CIFAR10\", \"classes.10\", \"-t1\"]\n",
    "elif dtype == \"NovelNet\":\n",
    "    indicators = [\"NovelNet\", \"-avg\"]\n",
    "    t1_indicators = [\"NovelNet\", \"-t1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(\"results\")\n",
    "result_dicts = [\n",
    "    load_res(f)\n",
    "    for f in files\n",
    "    if f[-3:] == \"pkl\" and str_contains(indicators + [_alg_type], f) and not str_contains(['epochs.3'], f)\n",
    "]\n",
    "t1_dicts = [\n",
    "    load_res(f)\n",
    "    for f in files\n",
    "    if f[-3:] == \"pkl\" and str_contains(t1_indicators + [_alg_type], f) and not str_contains(['epochs.3'], f)\n",
    "]\n",
    "result_dict, t1_dict = avg_across_dicts(result_dicts), avg_across_dicts(t1_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-Statistic: 25.294089992116206\n",
      "P-value: 1.615668211794183e-15\n",
      "top mean: 0.40331381588084464, top std: 0.00568420874338027\n",
      "bottom mean: 0.3299116572371386, bottom std: 0.006594053524647546\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x200 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mpl.rcParams['axes.linewidth'] = 2\n",
    "\n",
    "mpl.rcParams['axes.spines.left'] = False\n",
    "plt.figure(dpi=100, figsize=(3, 2))\n",
    "f_var = {\n",
    "    k: (2 * v[-1]) / ((v_t1[0] - v_t1[-1]) * v[-1] + 1)\n",
    "    for v, v_t1, k in zip(result_dict.values(), t1_dict.values(), result_dict.keys())\n",
    "}\n",
    "if dtype == 'NovelNet':\n",
    "    f_var = remove_duplicate_keys(f_var)\n",
    "f_var = dict(sorted(f_var.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "x_red, x_blue, y_red, y_blue = [], [], [], []\n",
    "cnt = 1\n",
    "for idx, (key, f_val) in enumerate(zip(f_var.keys(), f_var.values())):\n",
    "    if idx < 10:\n",
    "        x_red.append(cnt), y_red.append(f_val)\n",
    "        cnt += 1\n",
    "    elif idx >= 110:\n",
    "        x_blue.append(cnt), y_blue.append(f_val)\n",
    "        cnt += 1\n",
    "\n",
    "plt.bar(x_blue, y_blue, color=\"mediumturquoise\", label=\"worst curricula\", width=1)\n",
    "plt.bar(x_red, y_red, color=\"lightcoral\", label=\"best curricula\", width=1)\n",
    "# plt.xlabel(\"curricula\", fontdict={'weight': 'bold', 'size': 21, 'fontname': 'TImes New Roman'})\n",
    "# plt.ylabel(\"F\", fontdict={'weight': 'bold', 'size': 21, 'fontname': 'TImes New Roman'})\n",
    "# plt.legend(loc=\"upper right\", fontsize=10)\n",
    "plt.tick_params(axis=\"x\", which=\"both\", bottom=False, top=False)\n",
    "plt.tick_params(axis=\"y\", which=\"both\", left=False, right=False)\n",
    "plt.ylim(0.1, 0.6)\n",
    "plt.yticks([], weight='bold', size=21)\n",
    "plt.xticks([1, 20], weight='bold', size=21)\n",
    "\n",
    "# Perform t-test\n",
    "t_statistic, p_value = stats.ttest_ind(y_red, y_blue)\n",
    "\n",
    "# Print the results\n",
    "print(\"T-Statistic:\", t_statistic)\n",
    "print(\"P-value:\", p_value)\n",
    "print(\"top mean: {}, top std: {}\".format(np.mean(y_red), np.std(y_red)))\n",
    "print(\"bottom mean: {}, bottom std: {}\".format(np.mean(y_blue), np.std(y_blue)))\n",
    "# plt.text(0.5, 0.62, \"p-value: {}\".format(f\"{p_value:.2e}\"), fontsize=11, color='black')\n",
    "# plt.savefig('paper.fig.fscores.bar__1010.{}.{}.png'.format(dtype, _alg_type), dpi=200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
